# Data-Cleaning-Project
ğŸ“Œ Overview

This is my first data cleaning project. I worked on cleaning an Amazon sales dataset to make it beginner-friendly, consistent, and ready for analysis.

ğŸ› ï¸ Steps I Took

â€¢ Removed duplicates â†’ kept only unique records.
â€¢ Dealt with NULL values â†’ dropped rows where data could not be imputed.
â€¢ Standardised dates â†’ ensured all were in a consistent format.
â€¢ Cleaned City/County (State) pairs â†’ corrected formatting and verified valid US locations.
â€¢ Checked quantities â†’ removed unrealistic values (such as 500, 999, 1000).
â€¢ Handled Sales outliers â†’ removed extreme, unrealistic figures.
â€¢ Verified Discounts â†’ ensured all values were between 0% and 80%.
â€¢ Confirmed unique IDs â†’ no duplicate IDs remained.
â€¢ Left negative profit rows â†’ kept these as they can occur in real-world data (e.g. heavy discounts or loss-making sales).

âš ï¸ Notes

â€¢ Dataset is now clean and consistent.
â€¢ Outliers that were reasonable (such as negative profit from clearance sales) were deliberately kept.
â€¢ This project focused on practising basic cleaning skills in SQL and Excel/Pandas.

ğŸ“‚ Files

â€¢ Cleaned DCP.csv â†’ final cleaned dataset

ğŸš€ Next Steps

â¼ Use this cleaned dataset for beginner-friendly analysis (e.g. sales trends, profit by category, etc.).
â¼ Continue improving cleaning skills with more complex datasets.
